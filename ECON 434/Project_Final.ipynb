{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV\n",
    "#import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "#os.chdir(\"C:\\\\Users\\\\mmspe\\\\OneDrive\\\\Documents\\\\Python Scripts\\\\434\")\n",
    "data = pd.read_csv(\"Uber_dataset.csv\")\n",
    "\n",
    "#Add logs\n",
    "data[\"log_popestimate\"] = np.log(data[\"popestimate\"])\n",
    "data[\"log_employment\"] = np.log(data[\"employment\"])\n",
    "data[\"log_aveFareTotal\"] = np.log(data[\"aveFareTotal\"])\n",
    "data[\"log_VRHTotal\"] = np.log(data[\"VRHTotal\"])\n",
    "data[\"log_VOMSTotal\"] = np.log(data[\"VOMSTotal\"])\n",
    "data[\"log_VRMTotal\"] = np.log(data[\"VRMTotal\"])\n",
    "data[\"log_gasPrice\"] = np.log(data[\"gasPrice\"])\n",
    "\n",
    "#Drop nas\n",
    "data = data.dropna()\n",
    "\n",
    "#Dependant variable\n",
    "Y = np.log(data[\"UPTTotal\"])\n",
    "#First of two variations of variable of interest\n",
    "uber_dummy = np.array(data[\"treatUberX\"], ndmin = 2).T\n",
    "#Second of two variations of variable of interest\n",
    "uber_pen = np.array(data[\"treatGTNotStd\"], ndmin = 2).T\n",
    "\n",
    "#Vectorize controls for matrix multiplication\n",
    "lnpop = np.array(data[\"log_popestimate\"], ndmin = 2).T\n",
    "lnemp = np.array(data[\"log_employment\"], ndmin = 2).T\n",
    "lnfare = np.array(data[\"log_aveFareTotal\"], ndmin = 2).T\n",
    "lnvhours = np.array(data[\"log_VRHTotal\"], ndmin = 2).T\n",
    "lnnumv = np.array(data[\"log_VOMSTotal\"], ndmin = 2).T\n",
    "lnmiles = np.array(data[\"log_VRMTotal\"], ndmin = 2).T\n",
    "lngas = np.array(data[\"log_gasPrice\"], ndmin = 2).T\n",
    "\n",
    "controls =  np.concatenate((lnpop, lnemp, lnfare, lnvhours, lnnumv, \n",
    "                                  lnmiles, lngas), axis = 1)\n",
    "#Number of samples\n",
    "n = len(data) #58354 samples\n",
    "#Constant\n",
    "cons = np.ones([n ,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In OLS model 1:\n",
      "\n",
      "The coefficient for 'treatUberX' is  0.025221090638808657\n",
      "Standard Error is  0.011456778246592978\n",
      "95% confidence interval is [0.0027658052754864215,0.04767637600213089]\n",
      "\n",
      "The coefficient for 'treatGTNotStd' is  0.00425164205879151\n",
      "Standard Error is  0.0008496106012579795\n",
      "95% confidence interval is [0.00258640528032587,0.0059168788372571494]\n"
     ]
    }
   ],
   "source": [
    "#### Regressions ####\n",
    "#   Regression 1\n",
    "\n",
    "#       a) D = dummy\n",
    "\n",
    "X1a = np.concatenate((cons, uber_dummy, controls), axis = 1)\n",
    "\n",
    "betahat_1a = np.linalg.inv(X1a.T @ X1a) @ (X1a.T @ Y)\n",
    "ehat_1a = Y - X1a @ betahat_1a\n",
    "ehat_1a = np.array(ehat_1a, ndmin = 2).T\n",
    "\n",
    "Sigmahat_1a = (X1a * ehat_1a).T @ (X1a * ehat_1a) / n\n",
    "\n",
    "Qhat_1a = np.linalg.inv(X1a.T @ X1a / n)\n",
    "Vhat_1a = Qhat_1a @ Sigmahat_1a @ Qhat_1a\n",
    "sdhat_1a = np.sqrt(Vhat_1a[1 ,1]) / np.sqrt(n)\n",
    "cil_1a = betahat_1a[1] - 1.96 * sdhat_1a; cir_1a = betahat_1a[1] + 1.96 * sdhat_1a\n",
    "\n",
    "#       b) D = search intensity\n",
    "\n",
    "X1b = np.concatenate((cons, uber_pen, controls), axis = 1)\n",
    "\n",
    "betahat_1b = np.linalg.inv(X1b.T @ X1b) @ (X1b.T @ Y)\n",
    "ehat_1b = Y - X1b @ betahat_1b\n",
    "ehat_1b = np.array(ehat_1b, ndmin = 2).T\n",
    "\n",
    "Sigmahat_1b = (X1b * ehat_1b).T @ (X1b * ehat_1b) / n\n",
    "\n",
    "Qhat_1b = np.linalg.inv(X1b.T @ X1b / n)\n",
    "Vhat_1b = Qhat_1b @ Sigmahat_1b @ Qhat_1b\n",
    "sdhat_1b = np.sqrt(Vhat_1b[1 ,1]) / np.sqrt(n)\n",
    "cil_1b = betahat_1b[1] - 1.96 * sdhat_1b; cir_1b = betahat_1b[1] + 1.96 * sdhat_1b\n",
    "\n",
    "\n",
    "\n",
    "print('In OLS model 1:\\n')\n",
    "print(\"The coefficient for 'treatUberX' is \", betahat_1a[1])\n",
    "print(\"Standard Error is \", sdhat_1a)\n",
    "print(\"95% confidence interval is [\"+str(cil_1a)+\",\"+str(cir_1a)+\"]\")\n",
    "\n",
    "print(\"\\nThe coefficient for 'treatGTNotStd' is \", betahat_1b[1])\n",
    "print(\"Standard Error is \", sdhat_1b)\n",
    "print(\"95% confidence interval is [\"+str(cil_1b)+\",\"+str(cir_1b)+\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Regression 2\n",
    "#ð›¾i is a transit agency specific fixed effect; ð›¿t is a yearâ€“month specific fixed effect\n",
    "\n",
    "#       a) D = dummy\n",
    "\n",
    "#Create dummies for transit agency fixed effects\n",
    "agency_dummies = pd.get_dummies(data[\"agency\"])\n",
    "yrmon_dummies  = pd.get_dummies(data[\"dateSurvey\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In OLS model 2(including time and location effect):\n",
      "\n",
      "The coefficient for 'treatUberX' is  83.61157231029938\n",
      "Standard Error is  13.123927441415574\n",
      "95% confidence interval is [57.888674525124856,109.3344700954739]\n",
      "\n",
      "The coefficient for 'treatGTNotStd' is  7.794702525612877\n",
      "Standard Error is  12.342584472257613\n",
      "95% confidence interval is [-16.396763040012043,31.986168091237797]\n"
     ]
    }
   ],
   "source": [
    "X2a = np.concatenate((uber_dummy, agency_dummies, yrmon_dummies, controls), axis = 1)\n",
    "\n",
    "betahat_2a = np.linalg.inv(X2a.T @ X2a) @ (X2a.T @ Y)\n",
    "ehat_2a = Y - X2a @ betahat_2a\n",
    "ehat_2a = np.array(ehat_2a, ndmin = 2).T\n",
    "\n",
    "Sigmahat_2a = (X2a * ehat_2a).T @ (X2a * ehat_2a) / n\n",
    "\n",
    "Qhat_2a = np.linalg.inv(X2a.T @ X2a / n)\n",
    "Vhat_2a = Qhat_2a @ Sigmahat_2a @ Qhat_2a\n",
    "sdhat_2a = np.sqrt(Vhat_2a[0 ,0]) / np.sqrt(n)\n",
    "cil_2a = betahat_2a[0] - 1.96 * sdhat_2a; cir_2a = betahat_2a[0] + 1.96 * sdhat_2a\n",
    "\n",
    "#       b) D = search intensity\n",
    "\n",
    "X2b = np.concatenate((uber_pen, agency_dummies, \n",
    "                      yrmon_dummies, controls), axis = 1)\n",
    "\n",
    "betahat_2b = np.linalg.inv(X2b.T @ X2b) @ (X2b.T @ Y)\n",
    "ehat_2b = Y - X2b @ betahat_2b\n",
    "ehat_2b = np.array(ehat_2b, ndmin = 2).T\n",
    "\n",
    "Sigmahat_2b = (X2b * ehat_2b).T @ (X2b * ehat_2b) / n\n",
    "\n",
    "Qhat_2b = np.linalg.inv(X2b.T @ X2b / n)\n",
    "Vhat_2b = Qhat_2b @ Sigmahat_2b @ Qhat_2b\n",
    "sdhat_2b = np.sqrt(Vhat_2b[0 ,0]) / np.sqrt(n)\n",
    "cil_2b = betahat_2b[0] - 1.96 * sdhat_2b; cir_2b = betahat_2b[0] + 1.96 * sdhat_2b\n",
    "\n",
    "\n",
    "\n",
    "print('In OLS model 2(including time and location effect):\\n')\n",
    "print(\"The coefficient for 'treatUberX' is \", betahat_2a[0])\n",
    "print(\"Standard Error is \", sdhat_2a)\n",
    "print(\"95% confidence interval is [\"+str(cil_2a)+\",\"+str(cir_2a)+\"]\")\n",
    "\n",
    "print(\"\\nThe coefficient for 'treatGTNotStd' is \", betahat_2b[0])\n",
    "print(\"Standard Error is \", sdhat_2b)\n",
    "print(\"95% confidence interval is [\"+str(cil_2b)+\",\"+str(cir_2b)+\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Regression 3-----IMPORTANT\n",
    "\n",
    "#   a) D = dummy\n",
    "\n",
    "#Calculate median population: 1304926\n",
    "median_pop = np.median(data[\"popestimate\"])\n",
    "#Create dummy\n",
    "data[\"pop_med_dummy\"] = (data[\"popestimate\"] > median_pop).astype(int)\n",
    "#Create interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"pop_med_int\"] = data[\"pop_med_dummy\"] * data[\"treatUberX\"]\n",
    "#pop_med_dum = np.array(data[\"pop_med_dummy\"], ndmin = 2).T\n",
    "pop_med_int = np.array(data[\"pop_med_int\"], ndmin = 2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3a = np.concatenate((uber_dummy, pop_med_int, agency_dummies, \n",
    "                      yrmon_dummies, controls), axis = 1)\n",
    "\n",
    "betahat_3a = np.linalg.inv(X3a.T @ X3a) @ (X3a.T @ Y)\n",
    "ehat_3a = Y - X3a @ betahat_3a\n",
    "ehat_3a = np.array(ehat_3a, ndmin = 2).T\n",
    "\n",
    "Sigmahat_3a = (X3a * ehat_3a).T @ (X3a * ehat_3a) / n\n",
    "\n",
    "Qhat_3a = np.linalg.inv(X3a.T @ X3a / n)\n",
    "Vhat_3a = Qhat_3a @ Sigmahat_3a @ Qhat_3a\n",
    "sdhat_3a = np.sqrt(Vhat_3a[0 ,0]) / np.sqrt(n)\n",
    "cil_3a = betahat_3a[0] - 1.96 * sdhat_3a; cir_3a = betahat_3a[0] + 1.96 * sdhat_3a\n",
    "\n",
    "sdhat_3a_pop = np.sqrt(Vhat_3a[1 ,1]) / np.sqrt(n)\n",
    "\n",
    "cil_3a_pop = betahat_3a[1] - 1.96 * sdhat_3a_pop\n",
    "cir_3a_pop = betahat_3a[1] + 1.96 * sdhat_3a_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   b) D = search intensity\n",
    "\n",
    "#Create interaction\n",
    "data[\"pop_med_int_pen\"] = data[\"pop_med_dummy\"] * data[\"treatGTNotStd\"]\n",
    "pop_med_int_pen = np.array(data[\"pop_med_int_pen\"], ndmin = 2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uber_dummy</th>\n",
       "      <th>Above_median_pop*Uber_dummy</th>\n",
       "      <th>Uber_pen</th>\n",
       "      <th>Above_median_pop*Uber_pen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coef</th>\n",
       "      <td>-4.736869</td>\n",
       "      <td>59.390126</td>\n",
       "      <td>6.017821</td>\n",
       "      <td>-0.288028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>29.508157</td>\n",
       "      <td>26.509216</td>\n",
       "      <td>2.322999</td>\n",
       "      <td>1.839020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Uber_dummy  Above_median_pop*Uber_dummy  Uber_pen  \\\n",
       "coef   -4.736869                    59.390126  6.017821   \n",
       "SE     29.508157                    26.509216  2.322999   \n",
       "\n",
       "      Above_median_pop*Uber_pen  \n",
       "coef                  -0.288028  \n",
       "SE                     1.839020  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3b = np.concatenate((uber_pen, pop_med_int_pen, agency_dummies, \n",
    "                      yrmon_dummies, controls), axis = 1)\n",
    "\n",
    "betahat_3b = np.linalg.inv(X3b.T @ X3b) @ (X3b.T @ Y)\n",
    "ehat_3b = Y - X3b @ betahat_3b\n",
    "ehat_3b = np.array(ehat_3b, ndmin = 2).T\n",
    "\n",
    "Sigmahat_3b = (X3b * ehat_3b).T @ (X3b * ehat_3b) / n\n",
    "\n",
    "Qhat_3b = np.linalg.inv(X3b.T @ X3b / n)\n",
    "Vhat_3b = Qhat_3b @ Sigmahat_3b @ Qhat_3b\n",
    "sdhat_3b = np.sqrt(Vhat_3b[0 ,0]) / np.sqrt(n)\n",
    "cil_3b = betahat_3b[0] - 1.96 * sdhat_3b; cir_3b = betahat_3b[0] + 1.96 * sdhat_3b\n",
    "\n",
    "sdhat_3b_pop = np.sqrt(Vhat_3b[1 ,1]) / np.sqrt(n)\n",
    "\n",
    "cil_3b_pop = betahat_3b[1] - 1.96 * sdhat_3b_pop\n",
    "cir_3b_pop = betahat_3b[1] + 1.96 * sdhat_3b_pop\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pop_OLS = pd.DataFrame([[betahat_3a[0],betahat_3a[1],betahat_3b[0],betahat_3b[1]],\n",
    "                          [sdhat_3a,sdhat_3a_pop, sdhat_3b,sdhat_3b_pop]], \n",
    "                          columns=['Uber_dummy','Above_median_pop*Uber_dummy',\n",
    "                                   'Uber_pen', 'Above_median_pop*Uber_pen'],\n",
    "                         index=['coef','SE'])\n",
    "\n",
    "pop_OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Regression 4----IMPORTANT\n",
    "\n",
    "#Calculate median rides: \n",
    "median_rides = np.median(data[\"UPTTotal\"])\n",
    "#Create dummy\n",
    "data[\"rides_med_dummy\"] = (data[\"UPTTotal\"] > median_rides).astype(int)\n",
    "#Create interaction\n",
    "data[\"rides_med_int\"] = data[\"rides_med_dummy\"] * data[\"treatUberX\"]\n",
    "#rides_med_dum = np.array(data[\"rides_med_dummy\"], ndmin = 2).T\n",
    "rides_med_int = np.array(data[\"rides_med_dummy\"], ndmin = 2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4a = np.concatenate((uber_dummy, rides_med_int, agency_dummies, \n",
    "                      yrmon_dummies, controls), axis = 1)\n",
    "\n",
    "betahat_4a = np.linalg.inv(X4a.T @ X4a) @ (X4a.T @ Y)\n",
    "ehat_4a = Y - X4a @ betahat_4a\n",
    "ehat_4a = np.array(ehat_4a, ndmin = 2).T\n",
    "\n",
    "Sigmahat_4a = (X4a * ehat_4a).T @ (X4a * ehat_4a) / n\n",
    "\n",
    "Qhat_4a = np.linalg.inv(X4a.T @ X4a / n)\n",
    "Vhat_4a = Qhat_4a @ Sigmahat_4a @ Qhat_4a\n",
    "sdhat_4a = np.sqrt(Vhat_4a[0 ,0]) / np.sqrt(n)\n",
    "cil_4a = betahat_4a[0] - 1.96 * sdhat_4a; cir_4a = betahat_4a[0] + 1.96 * sdhat_4a\n",
    "\n",
    "sdhat_4a_rides = np.sqrt(Vhat_4a[1 ,1]) / np.sqrt(n)\n",
    "\n",
    "cil_4a_rides = betahat_4a[1] - 1.96 * sdhat_4a_rides\n",
    "cir_4a_rides = betahat_4a[1] + 1.96 * sdhat_4a_rides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   b) D = search intensity\n",
    "\n",
    "data[\"rides_med_int_pen\"] = data[\"rides_med_dummy\"] * data[\"treatGTNotStd\"]\n",
    "rides_med_int_pen = np.array(data[\"rides_med_int_pen\"], ndmin = 2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uber_dummy</th>\n",
       "      <th>Above_median_rides*Uber_dummy</th>\n",
       "      <th>Uber_pen</th>\n",
       "      <th>Above_median_rides*Uber_pen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coef</th>\n",
       "      <td>-240.145558</td>\n",
       "      <td>38.252774</td>\n",
       "      <td>4.630442</td>\n",
       "      <td>13.278537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>18.237347</td>\n",
       "      <td>11.742337</td>\n",
       "      <td>2.075298</td>\n",
       "      <td>1.757332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Uber_dummy  Above_median_rides*Uber_dummy  Uber_pen  \\\n",
       "coef -240.145558                      38.252774  4.630442   \n",
       "SE     18.237347                      11.742337  2.075298   \n",
       "\n",
       "      Above_median_rides*Uber_pen  \n",
       "coef                    13.278537  \n",
       "SE                       1.757332  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4b = np.concatenate((uber_pen, rides_med_int_pen, agency_dummies, \n",
    "                      yrmon_dummies, controls), axis = 1)\n",
    "\n",
    "betahat_4b = np.linalg.inv(X4b.T @ X4b) @ (X4b.T @ Y)\n",
    "ehat_4b = Y - X3b @ betahat_4b\n",
    "ehat_4b = np.array(ehat_4b, ndmin = 2).T\n",
    "\n",
    "Sigmahat_4b = (X4b * ehat_4b).T @ (X4b * ehat_4b) / n\n",
    "\n",
    "Qhat_4b = np.linalg.inv(X4b.T @ X4b / n)\n",
    "Vhat_4b = Qhat_4b @ Sigmahat_4b @ Qhat_4b\n",
    "sdhat_4b = np.sqrt(Vhat_4b[0 ,0]) / np.sqrt(n)\n",
    "cil_4b = betahat_4b[0] - 1.96 * sdhat_4b; cir_4b = betahat_4b[0] + 1.96 * sdhat_4b\n",
    "\n",
    "sdhat_4b_rides = np.sqrt(Vhat_4b[1 ,1]) / np.sqrt(n)\n",
    "\n",
    "cil_4b_rides = betahat_4b[1] - 1.96 * sdhat_4b_rides\n",
    "cir_4b_rides = betahat_4b[1] + 1.96 * sdhat_4b_rides\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rides_OLS = pd.DataFrame([[betahat_4a[0],betahat_4a[1],betahat_4b[0],betahat_4b[1]],\n",
    "                          [sdhat_4a,sdhat_4a_rides, sdhat_4b,sdhat_4b_rides]], \n",
    "                          columns=['Uber_dummy','Above_median_rides*Uber_dummy',\n",
    "                                   'Uber_pen', 'Above_median_rides*Uber_pen'],\n",
    "                         index=['coef','SE'])\n",
    "\n",
    "rides_OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Regression 5\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "#   a) D = dummy\n",
    "\n",
    "#Rescale controls\n",
    "muhat_scale = np.mean(controls,axis = 0)\n",
    "stdhat_scale = np.std(controls,axis = 0)\n",
    "controls_scaled = (controls - muhat_scale )/ stdhat_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5a = np.concatenate((uber_dummy, pop_med_int, agency_dummies, \n",
    "                      yrmon_dummies, controls_scaled), axis = 1)\n",
    "\n",
    "\n",
    "#run lasso\n",
    "lasso5a = LassoCV(cv = 5, fit_intercept=False,  random_state=0)\n",
    "lasso5a.fit(X5a ,Y)\n",
    "coef5a = lasso5a.coef_\n",
    "sel5a = (coef5a != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   b) D = search intensity\n",
    "\n",
    "#Rescale\n",
    "muhat_scale_pen = np.mean(uber_pen)\n",
    "stdhat_scale_pen = np.std(uber_pen)\n",
    "uber_pen_scaled = (uber_pen - muhat_scale_pen) / stdhat_scale_pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso_Uber_dummy</th>\n",
       "      <th>lasso_Above_med_pop*Uber_dummy</th>\n",
       "      <th>lasso_Uber_pen</th>\n",
       "      <th>lasso_Above_med_pop*Uber_pen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coef</th>\n",
       "      <td>0.875916</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-3.225298</td>\n",
       "      <td>1.111046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lasso_Uber_dummy  lasso_Above_med_pop*Uber_dummy  lasso_Uber_pen  \\\n",
       "coef          0.875916                            -0.0       -3.225298   \n",
       "\n",
       "      lasso_Above_med_pop*Uber_pen  \n",
       "coef                      1.111046  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X5b = np.concatenate((uber_pen_scaled, pop_med_int_pen, agency_dummies, \n",
    "                      yrmon_dummies, controls_scaled), axis = 1)\n",
    "\n",
    "lasso5b = LassoCV(cv = 5, fit_intercept=False,  random_state=0)\n",
    "lasso5b.fit(X5b, Y)\n",
    "coef5b = lasso5b.coef_\n",
    "sel5b = (coef5b != 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pop_lasso = pd.DataFrame([[coef5a[0],coef5a[1],coef5b[0],coef5b[1]]],\n",
    "                         columns=['lasso_Uber_dummy','lasso_Above_med_pop*Uber_dummy',\n",
    "                                   'lasso_Uber_pen', 'lasso_Above_med_pop*Uber_pen'],\n",
    "                          index=['coef'])\n",
    "\n",
    "pop_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso_Uber_dummy</th>\n",
       "      <th>lasso_Above_med_pop*Uber_dummy</th>\n",
       "      <th>lasso_Uber_pen</th>\n",
       "      <th>lasso_Above_med_pop*Uber_pen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coef</th>\n",
       "      <td>3.384813</td>\n",
       "      <td>5.449507</td>\n",
       "      <td>-0.983681</td>\n",
       "      <td>0.680361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lasso_Uber_dummy  lasso_Above_med_pop*Uber_dummy  lasso_Uber_pen  \\\n",
       "coef          3.384813                        5.449507       -0.983681   \n",
       "\n",
       "      lasso_Above_med_pop*Uber_pen  \n",
       "coef                      0.680361  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   Regression 6\n",
    "\n",
    "#   a) D = dummy\n",
    "\n",
    "X6a = np.concatenate((uber_dummy, rides_med_int, agency_dummies, \n",
    "                      yrmon_dummies, controls_scaled), axis = 1)\n",
    "\n",
    "#run lasso\n",
    "lasso6a = LassoCV(cv = 5, fit_intercept=False,  random_state=0)\n",
    "lasso6a.fit(X6a, Y)\n",
    "coef6a = lasso6a.coef_\n",
    "sel6a = (coef6a != 0)\n",
    "\n",
    "\n",
    "#   b) D = search intensity\n",
    "\n",
    "X6b = np.concatenate((uber_pen_scaled, rides_med_int_pen, agency_dummies, \n",
    "                      yrmon_dummies, controls_scaled), axis = 1)\n",
    "\n",
    "lasso6b = LassoCV(cv = 5, fit_intercept=False,  random_state=0)\n",
    "lasso6b.fit(X6b, Y)\n",
    "coef6b = lasso6b.coef_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rides_lasso = pd.DataFrame([[coef6a[0],coef6a[1],coef6b[0],coef6b[1]]],\n",
    "                           columns=['lasso_Uber_dummy','lasso_Above_med_pop*Uber_dummy',\n",
    "                                   'lasso_Uber_pen', 'lasso_Above_med_pop*Uber_pen'],\n",
    "                          index=['coef'])\n",
    "\n",
    "rides_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dblasso_Uber_dummy</th>\n",
       "      <th>dblasso_Above_med*Uber_dummy</th>\n",
       "      <th>dblasso_Uber_pen</th>\n",
       "      <th>dblasso_Above_med*Uber_pen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coef</th>\n",
       "      <td>[0.13101898349087987]</td>\n",
       "      <td>[0.11274623630591989]</td>\n",
       "      <td>[0.13921251994851558]</td>\n",
       "      <td>[0.1310502598460473]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dblasso_Uber_dummy dblasso_Above_med*Uber_dummy  \\\n",
       "coef  [0.13101898349087987]        [0.11274623630591989]   \n",
       "\n",
       "           dblasso_Uber_pen dblasso_Above_med*Uber_pen  \n",
       "coef  [0.13921251994851558]       [0.1310502598460473]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   Regression 7---DOUBLE LASSO\n",
    "\n",
    "#  Regresion 7.1 --- For population(corresponding to regression 5)\n",
    "#from sklearn.linear_model import MultiTaskLassoCV\n",
    "\n",
    "#       a) D= dummy\n",
    "#1st stage--same as regression 5 \n",
    "coef7ia_1 = lasso5a.coef_.copy()\n",
    "\n",
    "#2nd stage\n",
    "X7ia = np.concatenate((agency_dummies, yrmon_dummies, controls_scaled), axis = 1)\n",
    "\n",
    "#fit on uber_dummy \n",
    "lasso7ia_21 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=10000).fit(X7ia, uber_dummy)\n",
    "coef7ia_21 = lasso7ia_21.coef_\n",
    "ehat7ia_21 = uber_dummy.T- coef7ia_21.T @ X7ia.T\n",
    "\n",
    "#fit on pop_med_int\n",
    "lasso7ia_22 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=10000).fit(X7ia, pop_med_int)\n",
    "coef7ia_22 = lasso7ia_22.coef_\n",
    "ehat7ia_22 = pop_med_int.T- coef7ia_22.T @ X7ia.T\n",
    "\n",
    "#Calculate alpha\n",
    "alpha7ia_B1 = (np.array(Y - X7ia @ coef7ia_1[2:]) \n",
    "              @ ehat7ia_21.T) @ np.linalg.inv(uber_dummy.T @ (ehat7ia_21).T) \n",
    "\n",
    "alpha7ia_B2 = (np.array(Y - X7ia @ coef7ia_1[2:]) \n",
    "              @ ehat7ia_22.T) @ np.linalg.inv(pop_med_int.T @ (ehat7ia_22).T) \n",
    "\n",
    "\n",
    "#       b) D = search intensity\n",
    "\n",
    "#1st stage--same as regression 5 \n",
    "coef7ib_1 = lasso5b.coef_.copy()\n",
    "\n",
    "#2nd stage\n",
    "X7ib = np.concatenate((agency_dummies,yrmon_dummies, controls_scaled), axis = 1)\n",
    "\n",
    "#fit on uber_pen\n",
    "lasso7ib_21 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=10000).fit(X7ib, uber_pen)\n",
    "coef7ib_21 = lasso7ib_21.coef_\n",
    "ehat7ib_21 = uber_pen.T- coef7ib_21.T @ X7ib.T\n",
    "\n",
    "#fit on pop_med_int_pen\n",
    "lasso7ib_22 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=10000).fit(X7ib, pop_med_int_pen)\n",
    "coef7ib_22 = lasso7ib_22.coef_\n",
    "ehat7ib_22 = pop_med_int_pen.T- coef7ib_22.T @ X7ib.T\n",
    "\n",
    "#Calculate alpha\n",
    "alpha7ib_B1 = (np.array(Y - X7ib @ coef7ib_1[2:]) \n",
    "              @ ehat7ib_21.T) @ np.linalg.inv(uber_pen.T @ (ehat7ib_21).T) \n",
    "\n",
    "alpha7ib_B2 = (np.array(Y - X7ib @ coef7ib_1[2:]) \n",
    "              @ ehat7ib_22.T) @ np.linalg.inv(pop_med_int_pen.T @ (ehat7ib_22).T) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pop_dblasso = pd.DataFrame([[alpha7ia_B1,alpha7ia_B2,alpha7ib_B1,alpha7ib_B2]],\n",
    "                         columns=['dblasso_Uber_dummy','dblasso_Above_med*Uber_dummy',\n",
    "                                   'dblasso_Uber_pen', 'dblasso_Above_med*Uber_pen'],\n",
    "                          index=['coef'])\n",
    "\n",
    "pop_dblasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dblasso_Uber_dummy</th>\n",
       "      <th>dblasso_Above_med*Uber_dummy</th>\n",
       "      <th>dblasso_Uber_pen</th>\n",
       "      <th>dblasso_Above_med*Uber_pen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coef</th>\n",
       "      <td>[0.9625258688873952]</td>\n",
       "      <td>[3.6022486717742774]</td>\n",
       "      <td>[0.11751958756863312]</td>\n",
       "      <td>[0.10038554065880148]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dblasso_Uber_dummy dblasso_Above_med*Uber_dummy  \\\n",
       "coef  [0.9625258688873952]         [3.6022486717742774]   \n",
       "\n",
       "           dblasso_Uber_pen dblasso_Above_med*Uber_pen  \n",
       "coef  [0.11751958756863312]      [0.10038554065880148]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Regresion 7.2 --- For rides(corresponding to regression 6)\n",
    "\n",
    "#       a) D= dummy\n",
    "#1st stage--same as regression 6\n",
    "coef7iia_1 = lasso6a.coef_.copy()\n",
    "\n",
    "#2nd stage\n",
    "X7iia = np.concatenate((agency_dummies,yrmon_dummies, controls_scaled), axis = 1)\n",
    "\n",
    "#fit on uber_dummy \n",
    "lasso7iia_21 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=10000).fit(X7iia,uber_dummy)\n",
    "coef7iia_21 = lasso7iia_21.coef_\n",
    "ehat7iia_21 = uber_dummy.T- coef7iia_21.T @ X7iia.T\n",
    "\n",
    "#fit on rides_med_int\n",
    "lasso7iia_22 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=10000).fit(X7iia,rides_med_int)\n",
    "coef7iia_22 = lasso7iia_22.coef_\n",
    "ehat7iia_22 = rides_med_int.T - coef7iia_22.T @ X7iia.T\n",
    "\n",
    "#Calculate alpha\n",
    "alpha7iia_B1 = (np.array(Y - X7iia @ coef7iia_1[2:]) \n",
    "              @ ehat7iia_21.T) @ np.linalg.inv(uber_dummy.T @ (ehat7iia_21).T) \n",
    "\n",
    "alpha7iia_B2 = (np.array(Y - X7iia @ coef7iia_1[2:]) \n",
    "              @ ehat7iia_22.T) @ np.linalg.inv(rides_med_int.T @ (ehat7iia_22).T) \n",
    "\n",
    "\n",
    "#       b) D = search intensity\n",
    "\n",
    "#1st stage--same as regression 6 \n",
    "coef7iib_1 = lasso6b.coef_.copy()\n",
    "\n",
    "#2nd stage\n",
    "X7iib = np.concatenate((agency_dummies,yrmon_dummies, controls_scaled), axis = 1)\n",
    "\n",
    "#fit on uber_pen\n",
    "lasso7iib_21 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=10000).fit(X7iib, uber_pen)\n",
    "coef7iib_21 = lasso7iib_21.coef_\n",
    "ehat7iib_21 = uber_pen.T - coef7iib_21.T @ X7iib.T\n",
    "\n",
    "#fit on rides_med_int_pen\n",
    "lasso7iib_22 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=10000).fit(X7iib, rides_med_int_pen)\n",
    "coef7iib_22 = lasso7iib_22.coef_\n",
    "ehat7iib_22 = rides_med_int_pen.T - coef7iib_22.T @ X7iib.T\n",
    "\n",
    "#Calculate alpha\n",
    "alpha7iib_B1 = (np.array(Y - X7iib @ coef7iib_1[2:]) \n",
    "              @ ehat7iib_21.T) @ np.linalg.inv(uber_pen.T @ (ehat7iib_21).T) \n",
    "\n",
    "alpha7iib_B2 = (np.array(Y - X7iib @ coef7iib_1[2:]) \n",
    "              @ ehat7iib_22.T) @ np.linalg.inv(rides_med_int_pen.T @ (ehat7iib_22).T) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rides_dblasso = pd.DataFrame([[alpha7iia_B1,alpha7iia_B2,alpha7iib_B1,alpha7iib_B2]],\n",
    "                         columns=['dblasso_Uber_dummy','dblasso_Above_med*Uber_dummy',\n",
    "                                   'dblasso_Uber_pen', 'dblasso_Above_med*Uber_pen'],\n",
    "                          index=['coef'])\n",
    "\n",
    "rides_dblasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Regression 8\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#Create interactions\n",
    "pol_int = PolynomialFeatures(degree=5, include_bias=False)\n",
    "int_controls = pol_int.fit_transform(controls)\n",
    "\n",
    "muhat_scale_int = np.mean(int_controls,axis = 0)\n",
    "stdhat_scale_int = np.std(int_controls,axis = 0)\n",
    "int_controls_scaled = (int_controls - muhat_scale_int )/ stdhat_scale_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso_Uber_dummy</th>\n",
       "      <th>lasso_Above_med_pop*Uber_dummy</th>\n",
       "      <th>lasso_Uber_pen</th>\n",
       "      <th>lasso_Above_med_pop*Uber_pen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coef</th>\n",
       "      <td>5.910821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.126856</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lasso_Uber_dummy  lasso_Above_med_pop*Uber_dummy  lasso_Uber_pen  \\\n",
       "coef          5.910821                             0.0        1.126856   \n",
       "\n",
       "      lasso_Above_med_pop*Uber_pen  \n",
       "coef                          -0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   a) D = dummy\n",
    "\n",
    "X8a = np.concatenate((uber_dummy, pop_med_int, agency_dummies, \n",
    "                      yrmon_dummies, int_controls_scaled), axis = 1)\n",
    "\n",
    "lasso8a = LassoCV(cv = 5, fit_intercept=False, max_iter=100000, random_state=0)\n",
    "lasso8a.fit(X8a ,Y)\n",
    "coef8a = lasso8a.coef_\n",
    "sel8a = (coef8a != 0)\n",
    "\n",
    "#   b) D = search intensity\n",
    "\n",
    "X8b = np.concatenate((uber_pen, pop_med_int_pen, agency_dummies, \n",
    "                      yrmon_dummies, int_controls_scaled), axis = 1)\n",
    "\n",
    "lasso8b = LassoCV(cv = 5, fit_intercept=False, max_iter=100000, random_state=0)\n",
    "lasso8b.fit(X8b, Y)\n",
    "coef8b = lasso8b.coef_\n",
    "sel8b = (coef8b != 0)\n",
    "\n",
    "\n",
    "\n",
    "pop_poly_lasso = pd.DataFrame([[coef8a[0],coef8a[1],coef8b[0],coef8b[1]]],\n",
    "                         columns=['lasso_Uber_dummy','lasso_Above_med_pop*Uber_dummy',\n",
    "                                   'lasso_Uber_pen', 'lasso_Above_med_pop*Uber_pen'],\n",
    "                          index=['coef'])\n",
    "\n",
    "pop_poly_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lasso_Uber_dummy</th>\n",
       "      <th>lasso_Above_med_pop*Uber_dummy</th>\n",
       "      <th>lasso_Uber_pen</th>\n",
       "      <th>lasso_Above_med_pop*Uber_pen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coef</th>\n",
       "      <td>3.087736</td>\n",
       "      <td>16.191179</td>\n",
       "      <td>1.126856</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lasso_Uber_dummy  lasso_Above_med_pop*Uber_dummy  lasso_Uber_pen  \\\n",
       "coef          3.087736                       16.191179        1.126856   \n",
       "\n",
       "      lasso_Above_med_pop*Uber_pen  \n",
       "coef                           0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   Regression 9\n",
    "\n",
    "#   a) D = dummy\n",
    "\n",
    "X9a = np.concatenate((uber_dummy, rides_med_int, agency_dummies, \n",
    "                      yrmon_dummies, int_controls_scaled), axis = 1)\n",
    "\n",
    "\n",
    "lasso9a = LassoCV(cv = 5, fit_intercept=False, max_iter=100000, random_state=0)\n",
    "lasso9a.fit(X9a ,Y)\n",
    "coef9a = lasso9a.coef_\n",
    "sel9a = (coef9a != 0)\n",
    "\n",
    "#   b) D = search intensity\n",
    "\n",
    "X9b = np.concatenate((uber_pen, rides_med_int_pen, agency_dummies, \n",
    "                      yrmon_dummies, int_controls_scaled), axis = 1)\n",
    "\n",
    "lasso9b = LassoCV(cv = 5, fit_intercept=False, max_iter=100000, random_state=0)\n",
    "lasso9b.fit(X9b ,Y)\n",
    "coef9b = lasso9b.coef_\n",
    "sel9b = (coef9b != 0)\n",
    "\n",
    "\n",
    "\n",
    "rides_poly_lasso = pd.DataFrame([[coef9a[0],coef9a[1],coef9b[0],coef9b[1]]],\n",
    "                           columns=['lasso_Uber_dummy','lasso_Above_med_pop*Uber_dummy',\n",
    "                                   'lasso_Uber_pen', 'lasso_Above_med_pop*Uber_pen'],\n",
    "                          index=['coef'])\n",
    "\n",
    "rides_poly_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dblasso_Uber_dummy</th>\n",
       "      <th>dblasso_Above_med*Uber_dummy</th>\n",
       "      <th>dblasso_Uber_pen</th>\n",
       "      <th>dblasso_Above_med*Uber_pen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coef</th>\n",
       "      <td>[2.4535138829457885]</td>\n",
       "      <td>[3.771263171517215]</td>\n",
       "      <td>[0.2153537868033235]</td>\n",
       "      <td>[0.9667746577498112]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dblasso_Uber_dummy dblasso_Above_med*Uber_dummy      dblasso_Uber_pen  \\\n",
       "coef  [2.4535138829457885]          [3.771263171517215]  [0.2153537868033235]   \n",
       "\n",
       "     dblasso_Above_med*Uber_pen  \n",
       "coef       [0.9667746577498112]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   Regression 10 ---DOUBLE LASSO\n",
    "\n",
    "#  Regresion 10.1 --- For population(corresponding to regression 8)\n",
    "\n",
    "#       a) D= dummy\n",
    "#1st stage--same as regression 8 \n",
    "coef10ia_1 = lasso8a.coef_.copy()\n",
    "\n",
    "#2nd stage\n",
    "X10ia = np.concatenate((agency_dummies, yrmon_dummies, int_controls_scaled), axis = 1)\n",
    "\n",
    "#fit on uber_dummy \n",
    "lasso10ia_21 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=100000).fit(X10ia, uber_dummy)\n",
    "coef10ia_21 = lasso10ia_21.coef_\n",
    "ehat10ia_21 = uber_dummy.T- coef10ia_21.T @ X10ia.T\n",
    "\n",
    "#fit on pop_med_int\n",
    "lasso10ia_22 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=100000).fit(X10ia, pop_med_int)\n",
    "coef10ia_22 = lasso10ia_22.coef_\n",
    "ehat10ia_22 = pop_med_int.T- coef10ia_22.T @ X10ia.T\n",
    "\n",
    "#Calculate alpha\n",
    "alpha10ia_B1 = (np.array(Y - X10ia @ coef10ia_1[2:]) \n",
    "              @ ehat10ia_21.T) @ np.linalg.inv(uber_dummy.T @ (ehat10ia_21).T) \n",
    "\n",
    "alpha10ia_B2 = (np.array(Y - X10ia @ coef10ia_1[2:]) \n",
    "              @ ehat10ia_22.T) @ np.linalg.inv(pop_med_int.T @ (ehat10ia_22).T) \n",
    "\n",
    "\n",
    "#       b) D = search intensity\n",
    "\n",
    "#1st stage--same as regression 8\n",
    "coef10ib_1 = lasso8b.coef_.copy()\n",
    "\n",
    "#2nd stage\n",
    "X10ib = np.concatenate((agency_dummies,yrmon_dummies, int_controls_scaled), axis = 1)\n",
    "\n",
    "#fit on uber_pen\n",
    "lasso10ib_21 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=100000).fit(X10ib, uber_pen)\n",
    "coef10ib_21 = lasso10ib_21.coef_\n",
    "ehat10ib_21 = uber_pen.T- coef10ib_21.T @ X10ib.T\n",
    "\n",
    "#fit on pop_med_int_pen\n",
    "lasso10ib_22 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=100000).fit(X10ib, pop_med_int_pen)\n",
    "coef10ib_22 = lasso10ib_22.coef_\n",
    "ehat10ib_22 = pop_med_int_pen.T- coef10ib_22.T @ X10ib.T\n",
    "\n",
    "#Calculate alpha\n",
    "alpha10ib_B1 = (np.array(Y - X10ib @ coef10ib_1[2:]) \n",
    "              @ ehat10ib_21.T) @ np.linalg.inv(uber_pen.T @ (ehat10ib_21).T) \n",
    "\n",
    "alpha10ib_B2 = (np.array(Y - X10ib @ coef10ib_1[2:]) \n",
    "              @ ehat10ib_22.T) @ np.linalg.inv(pop_med_int_pen.T @ (ehat10ib_22).T) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pop_poly_dblasso = pd.DataFrame([[alpha10ia_B1, alpha10ia_B2, alpha10ib_B1, alpha10ib_B2]],\n",
    "                         columns=['dblasso_Uber_dummy','dblasso_Above_med*Uber_dummy',\n",
    "                                   'dblasso_Uber_pen', 'dblasso_Above_med*Uber_pen'],\n",
    "                          index=['coef'])\n",
    "\n",
    "pop_poly_dblasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dblasso_Uber_dummy</th>\n",
       "      <th>dblasso_Above_med*Uber_dummy</th>\n",
       "      <th>dblasso_Uber_pen</th>\n",
       "      <th>dblasso_Above_med*Uber_pen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coef</th>\n",
       "      <td>[2.4473356854663693]</td>\n",
       "      <td>[5.2431600147322]</td>\n",
       "      <td>[0.2153537868033235]</td>\n",
       "      <td>[1.0676545691696027]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dblasso_Uber_dummy dblasso_Above_med*Uber_dummy      dblasso_Uber_pen  \\\n",
       "coef  [2.4473356854663693]            [5.2431600147322]  [0.2153537868033235]   \n",
       "\n",
       "     dblasso_Above_med*Uber_pen  \n",
       "coef       [1.0676545691696027]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Regresion 10.2 --- For rides (corresponding to regression 9)\n",
    "\n",
    "#       a) D= dummy\n",
    "#1st stage--same as regression 9 \n",
    "coef10iia_1 = lasso9a.coef_.copy()\n",
    "\n",
    "#2nd stage\n",
    "X10iia = np.concatenate((agency_dummies,yrmon_dummies,int_controls_scaled), axis = 1)\n",
    "\n",
    "#fit on uber_dummy \n",
    "lasso10iia_21 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=500000).fit(X10iia, uber_dummy)\n",
    "coef10iia_21 = lasso10iia_21.coef_\n",
    "ehat10iia_21 = uber_dummy.T- coef10iia_21.T @ X10iia.T\n",
    "\n",
    "#fit on rides_med_int\n",
    "lasso10iia_22 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=500000).fit(X10iia, rides_med_int)\n",
    "coef10iia_22 = lasso10iia_22.coef_\n",
    "ehat10iia_22 = pop_med_int.T- coef10iia_22.T @ X10iia.T\n",
    "\n",
    "#Calculate alpha\n",
    "alpha10iia_B1 = (np.array(Y - X10iia @ coef10iia_1[2:]) \n",
    "              @ ehat10iia_21.T) @ np.linalg.inv(uber_dummy.T @ (ehat10iia_21).T) \n",
    "\n",
    "alpha10iia_B2 = (np.array(Y - X10iia @ coef10iia_1[2:]) \n",
    "              @ ehat10iia_22.T) @ np.linalg.inv(rides_med_int.T @ (ehat10iia_22).T) \n",
    "\n",
    "\n",
    "#       b) D = search intensity\n",
    "\n",
    "#1st stage--same as regression 8\n",
    "coef10iib_1 = lasso9b.coef_.copy()\n",
    "\n",
    "#2nd stage\n",
    "X10iib = np.concatenate((agency_dummies,yrmon_dummies, int_controls_scaled), axis = 1)\n",
    "\n",
    "#fit on uber_pen\n",
    "lasso10iib_21 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=500000).fit(X10iib, uber_pen)\n",
    "coef10iib_21 = lasso10iib_21.coef_\n",
    "ehat10iib_21 = uber_pen.T- coef10iib_21.T @ X10iib.T\n",
    "\n",
    "#fit on rides_med_int_pen\n",
    "lasso10iib_22 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                      max_iter=500000).fit(X10iib, rides_med_int_pen)\n",
    "coef10iib_22 = lasso10iib_22.coef_\n",
    "ehat10iib_22 = rides_med_int_pen.T- coef10iib_22.T @ X10iib.T\n",
    "\n",
    "#Calculate alpha\n",
    "alpha10iib_B1 = (np.array(Y - X10iib @ coef10iib_1[2:]) \n",
    "              @ ehat10iib_21.T) @ np.linalg.inv(uber_pen.T @ (ehat10iib_21).T) \n",
    "\n",
    "alpha10iib_B2 = (np.array(Y - X10iib @ coef10iib_1[2:]) \n",
    "              @ ehat10iib_22.T) @ np.linalg.inv(rides_med_int_pen.T @ (ehat10iib_22).T) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rides_poly_dblasso = pd.DataFrame([[alpha10iia_B1, alpha10iia_B2, alpha10iib_B1, alpha10iib_B2]],\n",
    "                         columns=['dblasso_Uber_dummy','dblasso_Above_med*Uber_dummy',\n",
    "                                   'dblasso_Uber_pen', 'dblasso_Above_med*Uber_pen'],\n",
    "                          index=['coef'])\n",
    "\n",
    "rides_poly_dblasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D=dummy_Coef</th>\n",
       "      <th>D=dummy_SE</th>\n",
       "      <th>D=dummy_95%CI</th>\n",
       "      <th>D=pen_Coef</th>\n",
       "      <th>D=pen_SE</th>\n",
       "      <th>D=pen_95%CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OLS 1</th>\n",
       "      <td>0.025221</td>\n",
       "      <td>0.011457</td>\n",
       "      <td>(0.0028,0.0477)</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>(0.0026,0.0059)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLS 2</th>\n",
       "      <td>83.611572</td>\n",
       "      <td>13.123927</td>\n",
       "      <td>(57.8887,109.3345)</td>\n",
       "      <td>7.794703</td>\n",
       "      <td>12.342584</td>\n",
       "      <td>(-16.3968,31.9862)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       D=dummy_Coef  D=dummy_SE       D=dummy_95%CI  D=pen_Coef   D=pen_SE  \\\n",
       "OLS 1      0.025221    0.011457     (0.0028,0.0477)    0.004252   0.000850   \n",
       "OLS 2     83.611572   13.123927  (57.8887,109.3345)    7.794703  12.342584   \n",
       "\n",
       "              D=pen_95%CI  \n",
       "OLS 1     (0.0026,0.0059)  \n",
       "OLS 2  (-16.3968,31.9862)  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression 1&2 (OLS)\n",
    "ols_model = pd.DataFrame([[betahat_1a[1],sdhat_1a,\n",
    "                           \"(\"+str(round(cil_1a,4))+\",\"+str(round(cir_1a,4))+\")\",\n",
    "                           betahat_1b[1],sdhat_1b,\n",
    "                           \"(\"+str(round(cil_1b,4))+\",\"+str(round(cir_1b,4))+\")\"],\n",
    "                          [betahat_2a[0],sdhat_2a,\n",
    "                           \"(\"+str(round(cil_2a,4))+\",\"+str(round(cir_2a,4))+\")\",\n",
    "                           betahat_2b[0],sdhat_2b,\n",
    "                           \"(\"+str(round(cil_2b,4))+\",\"+str(round(cir_2b,4))+\")\"]], \n",
    "                          columns=['D=dummy_Coef','D=dummy_SE','D=dummy_95%CI',\n",
    "                                   'D=pen_Coef','D=pen_SE','D=pen_95%CI'],\n",
    "                         index=['OLS 1','OLS 2'])\n",
    "\n",
    "ols_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D=dummy</th>\n",
       "      <th>D=dummy*Above_med</th>\n",
       "      <th>D=pen</th>\n",
       "      <th>D=pen*Above_med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OLS3_pop</th>\n",
       "      <td>-4.7369(29.5082)</td>\n",
       "      <td>59.3901(26.5092)</td>\n",
       "      <td>6.0178(2.323)</td>\n",
       "      <td>-0.288(1.839)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLS4_rides</th>\n",
       "      <td>-240.1456(18.2373)</td>\n",
       "      <td>38.2528(11.7423)</td>\n",
       "      <td>4.6304(2.0753)</td>\n",
       "      <td>13.2785(1.7573)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso_pop</th>\n",
       "      <td>0.8759</td>\n",
       "      <td>-0</td>\n",
       "      <td>-3.2253</td>\n",
       "      <td>1.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso_rides</th>\n",
       "      <td>3.3848</td>\n",
       "      <td>5.4495</td>\n",
       "      <td>-0.9837</td>\n",
       "      <td>0.6804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DbLasso_pop</th>\n",
       "      <td>[0.131]</td>\n",
       "      <td>[0.1127]</td>\n",
       "      <td>[0.1392]</td>\n",
       "      <td>[0.1311]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DbLasso_rides</th>\n",
       "      <td>[0.9625]</td>\n",
       "      <td>[3.6022]</td>\n",
       "      <td>[0.1175]</td>\n",
       "      <td>[0.1004]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso_poly_pop</th>\n",
       "      <td>5.9108</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1269</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso_poly_rides</th>\n",
       "      <td>3.0877</td>\n",
       "      <td>16.1912</td>\n",
       "      <td>1.1269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DbLasso_poly_pop</th>\n",
       "      <td>[2.4535]</td>\n",
       "      <td>[3.7713]</td>\n",
       "      <td>[0.2154]</td>\n",
       "      <td>[0.9668]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DbLasso_poly_rides</th>\n",
       "      <td>[2.4473]</td>\n",
       "      <td>[5.2432]</td>\n",
       "      <td>[0.2154]</td>\n",
       "      <td>[1.0677]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               D=dummy D=dummy*Above_med           D=pen  \\\n",
       "OLS3_pop              -4.7369(29.5082)  59.3901(26.5092)   6.0178(2.323)   \n",
       "OLS4_rides          -240.1456(18.2373)  38.2528(11.7423)  4.6304(2.0753)   \n",
       "Lasso_pop                       0.8759                -0         -3.2253   \n",
       "Lasso_rides                     3.3848            5.4495         -0.9837   \n",
       "DbLasso_pop                    [0.131]          [0.1127]        [0.1392]   \n",
       "DbLasso_rides                 [0.9625]          [3.6022]        [0.1175]   \n",
       "Lasso_poly_pop                  5.9108                 0          1.1269   \n",
       "Lasso_poly_rides                3.0877           16.1912          1.1269   \n",
       "DbLasso_poly_pop              [2.4535]          [3.7713]        [0.2154]   \n",
       "DbLasso_poly_rides            [2.4473]          [5.2432]        [0.2154]   \n",
       "\n",
       "                    D=pen*Above_med  \n",
       "OLS3_pop              -0.288(1.839)  \n",
       "OLS4_rides          13.2785(1.7573)  \n",
       "Lasso_pop                     1.111  \n",
       "Lasso_rides                  0.6804  \n",
       "DbLasso_pop                [0.1311]  \n",
       "DbLasso_rides              [0.1004]  \n",
       "Lasso_poly_pop                   -0  \n",
       "Lasso_poly_rides                  0  \n",
       "DbLasso_poly_pop           [0.9668]  \n",
       "DbLasso_poly_rides         [1.0677]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regression 3-10 \n",
    "# 3-4: OLS, adding pop & rides\n",
    "# 5-6: Lasso, same as 3-4\n",
    "# 7: Double Lasso on 5&6\n",
    "# 8-9: Lasso, add poly\n",
    "# 10: Double Lasso on 8&9\n",
    "\n",
    "model_group = pd.DataFrame([\n",
    "    [str(round(betahat_3a[0],4))+\"(\"+str(round(sdhat_3a,4))+\")\",\n",
    "     str(round(betahat_3a[1],4))+\"(\"+str(round(sdhat_3a_pop,4))+\")\",\n",
    "     str(round(betahat_3b[0],4))+\"(\"+str(round(sdhat_3b,4))+\")\",\n",
    "     str(round(betahat_3b[1],4))+\"(\"+str(round(sdhat_3b_pop,4))+\")\"],\n",
    "    [str(round(betahat_4a[0],4))+\"(\"+str(round(sdhat_4a,4))+\")\",\n",
    "     str(round(betahat_4a[1],4))+\"(\"+str(round(sdhat_4a_rides,4))+\")\",\n",
    "     str(round(betahat_4b[0],4))+\"(\"+str(round(sdhat_4b,4))+\")\",\n",
    "     str(round(betahat_4b[1],4))+\"(\"+str(round(sdhat_4b_rides,4))+\")\"],\n",
    "    [round(coef5a[0],4),round(coef5a[1],4),round(coef5b[0],4),round(coef5b[1],4)],\n",
    "    [round(coef6a[0],4),round(coef6a[1],4),round(coef6b[0],4),round(coef6b[1],4)],\n",
    "    [np.round(alpha7ia_B1,4),np.round(alpha7ia_B2,4),np.round(alpha7ib_B1,4),\n",
    "     np.round(alpha7ib_B2,4)],\n",
    "    [np.round(alpha7iia_B1,4),np.round(alpha7iia_B2,4),np.round(alpha7iib_B1,4),\n",
    "     np.round(alpha7iib_B2,4)],\n",
    "    [round(coef8a[0],4),round(coef8a[1],4),round(coef8b[0],4),round(coef8b[1],4)],\n",
    "    [round(coef9a[0],4),round(coef9a[1],4),round(coef9b[0],4),round(coef9b[1],4)],\n",
    "    [np.round(alpha10ia_B1,4),np.round(alpha10ia_B2,4),np.round(alpha10ib_B1,4),\n",
    "     np.round(alpha10ib_B2,4)],\n",
    "    [np.round(alpha10iia_B1,4),np.round(alpha10iia_B2,4),np.round(alpha10iib_B1,4),\n",
    "     np.round(alpha10iib_B2,4)]],\n",
    "    columns=['D=dummy','D=dummy*Above_med','D=pen','D=pen*Above_med'],\n",
    "    index=['OLS3_pop','OLS4_rides','Lasso_pop','Lasso_rides','DbLasso_pop',\n",
    "           'DbLasso_rides','Lasso_poly_pop','Lasso_poly_rides',\n",
    "           'DbLasso_poly_pop','DbLasso_poly_rides'])\n",
    "\n",
    "model_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### BONUS REGRESSION 1-6 #####################\n",
    "\n",
    "#New D = dummy * search intensity\n",
    "\n",
    "#This will be equal to zero before Uber enters (when dummy=0), and equal to \n",
    "#the search intensity volume after. This combines the effects of Ubers presence\n",
    "#from the dummy variable with the size/populariy of uber from the search intensity\n",
    "\n",
    "#Bonus 1 - Reg 3 but with new D\n",
    "\n",
    "data[\"D_new\"] = data[\"treatUberX\"] * data[\"treatGTNotStd\"]\n",
    "D_new = np.array(data[\"D_new\"], ndmin = 2).T\n",
    "\n",
    "data[\"pop_int_new\"] = data[\"pop_med_dummy\"] * data[\"D_new\"]\n",
    "pop_int_new = np.array(data[\"pop_int_new\"], ndmin = 2).T\n",
    "\n",
    "#And we will fit into different regressions to see if it improve the result.\n",
    "\n",
    "\n",
    "Xbonus1_1 = np.concatenate((D_new, pop_int_new, agency_dummies, \n",
    "                      yrmon_dummies, controls), axis = 1)\n",
    "\n",
    "betahat_b1 = np.linalg.inv(Xbonus1_1.T @ Xbonus1_1) @ (Xbonus1_1.T @ Y)\n",
    "ehat_b1 = Y - Xbonus1_1 @ betahat_b1\n",
    "ehat_b1 = np.array(ehat_b1, ndmin = 2).T\n",
    "\n",
    "Sigmahat_b1 = (Xbonus1_1 * ehat_b1).T @ (Xbonus1_1 * ehat_b1) / n\n",
    "\n",
    "Qhat_b1 = np.linalg.inv(Xbonus1_1.T @ Xbonus1_1 / n)\n",
    "Vhat_b1 = Qhat_b1 @ Sigmahat_b1 @ Qhat_b1\n",
    "sdhat_b1 = np.sqrt(Vhat_b1[0 ,0]) / np.sqrt(n)\n",
    "\n",
    "sdhat_b1_pop = np.sqrt(Vhat_b1[1 ,1]) / np.sqrt(n)\n",
    "\n",
    "\n",
    "#Bonus 2 - Reg 4 but with new D\n",
    "\n",
    "data[\"rides_int_new\"] = data[\"rides_med_dummy\"] * data[\"D_new\"]\n",
    "rides_int_new = np.array(data[\"rides_int_new\"], ndmin = 2).T\n",
    "\n",
    "Xbonus_2 = np.concatenate((D_new, rides_int_new, agency_dummies, \n",
    "                      yrmon_dummies, controls), axis = 1)\n",
    "\n",
    "betahat_b2 = np.linalg.inv(Xbonus_2.T @ Xbonus_2) @ (Xbonus_2.T @ Y)\n",
    "ehat_b2 = Y - Xbonus_2 @ betahat_b2\n",
    "ehat_b2 = np.array(ehat_b2, ndmin = 2).T\n",
    "\n",
    "Sigmahat_b2 = (Xbonus_2 * ehat_b2).T @ (Xbonus_2 * ehat_b2) / n\n",
    "\n",
    "Qhat_b2 = np.linalg.inv(Xbonus_2.T @ Xbonus_2 / n)\n",
    "Vhat_b2 = Qhat_b2 @ Sigmahat_b2 @ Qhat_b2\n",
    "sdhat_b2 = np.sqrt(Vhat_b2[0 ,0]) / np.sqrt(n)\n",
    "\n",
    "sdhat_b2_rides = np.sqrt(Vhat_b2[1 ,1]) / np.sqrt(n)\n",
    "#Vhat_b2[1 ,1] is negative ????\n",
    "\n",
    "#Bonus 3 - Reg 5 with new D\n",
    "\n",
    "Xbonus_3 = np.concatenate((D_new, pop_int_new, agency_dummies, \n",
    "                      yrmon_dummies, controls_scaled), axis = 1)\n",
    "\n",
    "\n",
    "#run lasso\n",
    "lassob3 = LassoCV(cv = 5, fit_intercept=False,  random_state=0)\n",
    "lassob3.fit(Xbonus_3 ,Y)\n",
    "coefb3 = lassob3.coef_\n",
    "\n",
    "\n",
    "#Bonus 4 - Reg 6 with new D\n",
    "\n",
    "Xbonus_4 = np.concatenate((D_new, rides_int_new, agency_dummies, \n",
    "                      yrmon_dummies, controls_scaled), axis = 1)\n",
    "\n",
    "\n",
    "#run lasso\n",
    "lassob4 = LassoCV(cv = 5, fit_intercept=False,  random_state=0)\n",
    "lassob4.fit(Xbonus_4 ,Y)\n",
    "coefb4 = lassob4.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bonus 5 - Reg 8 with new D\n",
    "\n",
    "Xbonus_5 = np.concatenate((D_new, pop_int_new, agency_dummies, \n",
    "                      yrmon_dummies, int_controls_scaled), axis = 1)\n",
    "\n",
    "lassob5 = LassoCV(cv = 5, fit_intercept=False, max_iter=100000, random_state=0)\n",
    "lassob5.fit(Xbonus_5 ,Y)\n",
    "coefb5 = lassob5.coef_\n",
    "\n",
    "\n",
    "#Bonus 6 - Reg 9 with new D\n",
    "\n",
    "Xbonus_6 = np.concatenate((D_new, rides_int_new, agency_dummies, \n",
    "                      yrmon_dummies, int_controls_scaled), axis = 1)\n",
    "\n",
    "lassob6 = LassoCV(cv = 5, fit_intercept=False, max_iter=100000, random_state=0)\n",
    "lassob6.fit(Xbonus_6 ,Y)\n",
    "coefb6 = lassob6.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D_new</th>\n",
       "      <th>D_new*Above_med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bonus1_pop_OLS</th>\n",
       "      <td>-25.2238(2.1116)</td>\n",
       "      <td>22.7504(1.7522)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonus2_rides_OLS</th>\n",
       "      <td>-23.1685(1.999)</td>\n",
       "      <td>30.7578(nan)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonus3_pop_Lasso</th>\n",
       "      <td>0.7431</td>\n",
       "      <td>-0.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonus4_rides_Lasso</th>\n",
       "      <td>0.5311</td>\n",
       "      <td>-0.0113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonus5_pop_LassoPoly</th>\n",
       "      <td>0.7237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonus6_rides_LassoPoly</th>\n",
       "      <td>0.7237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   D_new  D_new*Above_med\n",
       "Bonus1_pop_OLS          -25.2238(2.1116)  22.7504(1.7522)\n",
       "Bonus2_rides_OLS         -23.1685(1.999)     30.7578(nan)\n",
       "Bonus3_pop_Lasso                  0.7431           -0.237\n",
       "Bonus4_rides_Lasso                0.5311          -0.0113\n",
       "Bonus5_pop_LassoPoly              0.7237                0\n",
       "Bonus6_rides_LassoPoly            0.7237                0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bonus Regression1-6: \n",
    "\n",
    "bonus_group1 = pd.DataFrame([\n",
    "    [str(round(betahat_b1[0],4))+\"(\"+str(round(sdhat_b1,4))+\")\",\n",
    "     str(round(betahat_b1[1],4))+\"(\"+str(round(sdhat_b1_pop,4))+\")\"],\n",
    "    [str(round(betahat_b2[0],4))+\"(\"+str(round(sdhat_b2,4))+\")\",\n",
    "     str(round(betahat_b2[1],4))+\"(\"+str(round(sdhat_b2_rides,4))+\")\"],\n",
    "    [round(coefb3[0],4),round(coefb3[1],4)],[round(coefb4[0],4),round(coefb4[1],4)],\n",
    "    [round(coefb5[0],4),round(coefb5[1],4)],[round(coefb6[0],4),round(coefb6[1],4)]],\n",
    "    columns=['D_new','D_new*Above_med'], \n",
    "    index=['Bonus1_pop_OLS','Bonus2_rides_OLS','Bonus3_pop_Lasso','Bonus4_rides_Lasso',\n",
    "           'Bonus5_pop_LassoPoly','Bonus6_rides_LassoPoly'])\n",
    "\n",
    "bonus_group1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### BONUS REGRESSION 7- #####################\n",
    "\n",
    "#put the interaction of pop*dummy and rides*dummy in one model as the paper does and \n",
    "#fit OLS, Lasso rgeression\n",
    "\n",
    "#Bonus 7 - OLS but with both inteactions.\n",
    "\n",
    "# a) with D=dummy\n",
    "Xbonus7_1 = np.concatenate((uber_dummy, pop_med_int, rides_med_int, agency_dummies, \n",
    "                      yrmon_dummies, controls), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betahat_b7_1 = np.linalg.inv(Xbonus7_1.T @ Xbonus7_1) @ (Xbonus7_1.T @ Y)\n",
    "ehat_b7_1 = Y - Xbonus7_1 @ betahat_b7_1\n",
    "ehat_b7_1 = np.array(ehat_b7_1, ndmin = 2).T\n",
    "\n",
    "Sigmahat_b7_1 = (Xbonus7_1 * ehat_b7_1).T @ (Xbonus7_1 * ehat_b7_1) / n\n",
    "\n",
    "Qhat_b7_1 = np.linalg.inv(Xbonus7_1.T @ Xbonus7_1 / n)\n",
    "Vhat_b7_1 = Qhat_b7_1 @ Sigmahat_b7_1 @ Qhat_b7_1\n",
    "sdhat_b7_1 = np.sqrt(Vhat_b7_1[0 ,0]) / np.sqrt(n)\n",
    "\n",
    "sdhat_b7_1pop = np.sqrt(Vhat_b7_1[1 ,1]) / np.sqrt(n)\n",
    "sdhat_b7_1rides = np.sqrt(Vhat_b7_1[2 ,2]) / np.sqrt(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) with D=search intensity\n",
    "Xbonus7_2 = np.concatenate((uber_pen, pop_med_int_pen, rides_med_int_pen, \n",
    "                            agency_dummies, yrmon_dummies, controls), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "betahat_b7_2 = np.linalg.inv(Xbonus7_2.T @ Xbonus7_2) @ (Xbonus7_2.T @ Y)\n",
    "ehat_b7_2 = Y - Xbonus7_2 @ betahat_b7_2\n",
    "ehat_b7_2 = np.array(ehat_b7_2, ndmin = 2).T\n",
    "\n",
    "Sigmahat_b7_2 = (Xbonus7_2 * ehat_b7_2).T @ (Xbonus7_2 * ehat_b7_2) / n\n",
    "\n",
    "Qhat_b7_2 = np.linalg.inv(Xbonus7_2.T @ Xbonus7_2 / n)\n",
    "Vhat_b7_2 = Qhat_b7_2 @ Sigmahat_b7_2 @ Qhat_b7_2\n",
    "sdhat_b7_2 = np.sqrt(Vhat_b7_2[0 ,0]) / np.sqrt(n)\n",
    "\n",
    "sdhat_b7_2pop = np.sqrt(Vhat_b7_2[1 ,1]) / np.sqrt(n)\n",
    "sdhat_b7_2rides = np.sqrt(Vhat_b7_2[2 ,2]) / np.sqrt(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bonus 8 - Lasso but with both inteactions.\n",
    "\n",
    "# a) with D=dummy\n",
    "Xbonus8_1 = Xbonus7_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassob8_1 = LassoCV(cv = 5, fit_intercept=False, max_iter=100000, random_state=0)\n",
    "lassob8_1.fit(Xbonus8_1 ,Y)\n",
    "coefb8_1 = lassob8_1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) with D=search intensity\n",
    "Xbonus8_2 = Xbonus7_2.copy()\n",
    "\n",
    "lassob8_2 = LassoCV(cv = 5, fit_intercept=False, max_iter=100000, random_state=0)\n",
    "lassob8_2.fit(Xbonus8_2 ,Y)\n",
    "coefb8_2 = lassob8_2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bonus 9 - Lasso of Poly with both inteactions.\n",
    "\n",
    "# a) with D=dummy\n",
    "Xbonus9_1 =  np.concatenate((uber_dummy, pop_med_int, rides_med_int, agency_dummies, \n",
    "                      yrmon_dummies, controls_scaled), axis = 1)\n",
    "\n",
    "\n",
    "lassob9_1 = LassoCV(cv = 5, fit_intercept=False, max_iter=100000, random_state=0)\n",
    "lassob9_1.fit(Xbonus9_1 ,Y)\n",
    "coefb9_1 = lassob9_1.coef_\n",
    "\n",
    "# b) with D=search intensity\n",
    "Xbonus9_2 =  np.concatenate((uber_pen, pop_med_int_pen, rides_med_int_pen, \n",
    "                             agency_dummies, yrmon_dummies, controls_scaled), axis = 1)\n",
    "\n",
    "lassob9_2 = LassoCV(cv = 5, fit_intercept=False, max_iter=100000, random_state=0)\n",
    "lassob9_2.fit(Xbonus9_2 ,Y)\n",
    "coefb9_2 = lassob9_2.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\cecil\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Bonus 10 - DoubleLasso with both inteactions, corresponding to 8\n",
    "\n",
    "# a) with D=dummy\n",
    "#1st stage--same as Bonus 8_1 \n",
    "coefb10_1 = coefb8_1.copy()\n",
    "\n",
    "#2nd stage\n",
    "Xbonus10_1 = np.concatenate((agency_dummies, yrmon_dummies, controls_scaled), axis = 1)\n",
    "\n",
    "#fit on uber_dummy \n",
    "lassob10_11 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                       max_iter=10000).fit(Xbonus10_1, uber_dummy)\n",
    "coefb10_11 = lassob10_11.coef_\n",
    "ehatb10_11 = uber_dummy.T- coefb10_11.T @ Xbonus10_1.T\n",
    "\n",
    "#fit on pop_med_int\n",
    "lassob10_12 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                       max_iter=10000).fit(Xbonus10_1, pop_med_int)\n",
    "coefb10_12 = lassob10_12.coef_\n",
    "ehatb10_12 = pop_med_int.T- coefb10_12.T @ Xbonus10_1.T\n",
    "\n",
    "#fit on rides_med_int\n",
    "lassob10_13 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                       max_iter=10000).fit(Xbonus10_1, rides_med_int)\n",
    "coefb10_13 = lassob10_13.coef_\n",
    "ehatb10_13 = pop_med_int.T- coefb10_13.T @ Xbonus10_1.T\n",
    "\n",
    "\n",
    "#Calculate alpha\n",
    "alphab10_11 = (np.array(Y - Xbonus10_1 @ coefb10_1[3:]) \n",
    "              @ ehatb10_11.T) @ np.linalg.inv(uber_dummy.T @ (ehatb10_11).T) \n",
    "\n",
    "alphab10_12 = (np.array(Y - Xbonus10_1 @ coefb10_1[3:]) \n",
    "              @ ehatb10_12.T) @ np.linalg.inv(pop_med_int.T @ (ehatb10_12).T)\n",
    "\n",
    "alphab10_13 = (np.array(Y - Xbonus10_1 @ coefb10_1[3:]) \n",
    "              @ ehatb10_13.T) @ np.linalg.inv(rides_med_int.T @ (ehatb10_13).T)\n",
    "\n",
    "# b) with D=search intensity\n",
    "#1st stage--same as Bonus 8_2\n",
    "coefb10_2 = coefb8_2.copy()\n",
    "\n",
    "#2nd stage\n",
    "Xbonus10_2 = np.concatenate((agency_dummies, yrmon_dummies, controls_scaled), axis = 1)\n",
    "\n",
    "#fit on uber_dummy \n",
    "lassob10_21 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                       max_iter=10000).fit(Xbonus10_2, uber_pen)\n",
    "coefb10_21 = lassob10_21.coef_\n",
    "ehatb10_21 = uber_dummy.T- coefb10_21.T @ Xbonus10_2.T\n",
    "\n",
    "#fit on pop_med_int\n",
    "lassob10_22 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                       max_iter=10000).fit(Xbonus10_2, pop_med_int_pen)\n",
    "coefb10_22 = lassob10_22.coef_\n",
    "ehatb10_22 = pop_med_int_pen.T- coefb10_22.T @ Xbonus10_2.T\n",
    "\n",
    "#fit on rides_med_int\n",
    "lassob10_23 = LassoCV(cv = 5, fit_intercept=False,random_state=0, \n",
    "                       max_iter=10000).fit(Xbonus10_2, rides_med_int_pen)\n",
    "coefb10_23 = lassob10_23.coef_\n",
    "ehatb10_23 = pop_med_int_pen.T- coefb10_23.T @ Xbonus10_2.T\n",
    "\n",
    "\n",
    "#Calculate alpha\n",
    "alphab10_21 = (np.array(Y - Xbonus10_2 @ coefb10_2[3:]) \n",
    "              @ ehatb10_21.T) @ np.linalg.inv(uber_dummy.T @ (ehatb10_21).T) \n",
    "\n",
    "alphab10_22 = (np.array(Y - Xbonus10_2 @ coefb10_2[3:]) \n",
    "              @ ehatb10_22.T) @ np.linalg.inv(pop_med_int_pen.T @ (ehatb10_22).T)\n",
    "\n",
    "alphab10_23 = (np.array(Y - Xbonus10_2 @ coefb10_2[3:]) \n",
    "              @ ehatb10_23.T) @ np.linalg.inv(rides_med_int_pen.T @ (ehatb10_23).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>D*Above_med_pop</th>\n",
       "      <th>D*Above_med_rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bonus7_dummy_OLS</th>\n",
       "      <td>654.2071(24.4759)</td>\n",
       "      <td>-770.8443(24.2666)</td>\n",
       "      <td>-34.3373(15.0325)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonus7_pen_OLS</th>\n",
       "      <td>-71.3557(6.3558)</td>\n",
       "      <td>57.8901(4.1488)</td>\n",
       "      <td>28.2808(2.629)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonus8_dummy_Lasso</th>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonus8_pen_Lasso</th>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonus9_dummy_LassoPoly</th>\n",
       "      <td>2.983</td>\n",
       "      <td>0.4952</td>\n",
       "      <td>5.4612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonus9_pen_LassoPoly</th>\n",
       "      <td>1.1786</td>\n",
       "      <td>-0.4017</td>\n",
       "      <td>0.0241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonus10_dummy_DbLasso</th>\n",
       "      <td>[2.1153]</td>\n",
       "      <td>[1.8114]</td>\n",
       "      <td>[12.6196]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonus10_pen_DbLasso</th>\n",
       "      <td>[2.1153]</td>\n",
       "      <td>[0.3039]</td>\n",
       "      <td>[0.8207]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        D     D*Above_med_pop  \\\n",
       "Bonus7_dummy_OLS        654.2071(24.4759)  -770.8443(24.2666)   \n",
       "Bonus7_pen_OLS           -71.3557(6.3558)     57.8901(4.1488)   \n",
       "Bonus8_dummy_Lasso                     -0                  -0   \n",
       "Bonus8_pen_Lasso                       -0                  -0   \n",
       "Bonus9_dummy_LassoPoly              2.983              0.4952   \n",
       "Bonus9_pen_LassoPoly               1.1786             -0.4017   \n",
       "Bonus10_dummy_DbLasso            [2.1153]            [1.8114]   \n",
       "Bonus10_pen_DbLasso              [2.1153]            [0.3039]   \n",
       "\n",
       "                        D*Above_med_rides  \n",
       "Bonus7_dummy_OLS        -34.3373(15.0325)  \n",
       "Bonus7_pen_OLS             28.2808(2.629)  \n",
       "Bonus8_dummy_Lasso                      0  \n",
       "Bonus8_pen_Lasso                    0.015  \n",
       "Bonus9_dummy_LassoPoly             5.4612  \n",
       "Bonus9_pen_LassoPoly               0.0241  \n",
       "Bonus10_dummy_DbLasso           [12.6196]  \n",
       "Bonus10_pen_DbLasso              [0.8207]  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bonus Regression: \n",
    "\n",
    "bonus_group2 = pd.DataFrame([\n",
    "    [str(round(betahat_b7_1[0],4))+\"(\"+str(round(sdhat_b7_1,4))+\")\",\n",
    "     str(round(betahat_b7_1[1],4))+\"(\"+str(round(sdhat_b7_1pop,4))+\")\",\n",
    "     str(round(betahat_b7_1[2],4))+\"(\"+str(round(sdhat_b7_1rides,4))+\")\"],\n",
    "    [str(round(betahat_b7_2[0],4))+\"(\"+str(round(sdhat_b7_2,4))+\")\",\n",
    "     str(round(betahat_b7_2[1],4))+\"(\"+str(round(sdhat_b7_2pop,4))+\")\",\n",
    "     str(round(betahat_b7_2[2],4))+\"(\"+str(round(sdhat_b7_2rides,4))+\")\"],\n",
    "    [round(coefb8_1[0],4),round(coefb8_1[1],4),round(coefb8_1[2],4)],\n",
    "    [round(coefb8_2[0],4),round(coefb8_2[1],4),round(coefb8_2[2],4)],\n",
    "    [round(coefb9_1[0],4),round(coefb9_1[1],4),round(coefb9_1[2],4)],\n",
    "    [round(coefb9_2[0],4),round(coefb9_2[1],4),round(coefb9_2[2],4)],\n",
    "    [np.round(alphab10_11,4),np.round(alphab10_12,4),np.round(alphab10_13,4)],\n",
    "    [np.round(alphab10_21,4),np.round(alphab10_22,4),np.round(alphab10_23,4)]],\n",
    "    columns=['D','D*Above_med_pop','D*Above_med_rides'], \n",
    "    index=['Bonus7_dummy_OLS','Bonus7_pen_OLS','Bonus8_dummy_Lasso','Bonus8_pen_Lasso',\n",
    "          'Bonus9_dummy_LassoPoly','Bonus9_pen_LassoPoly','Bonus10_dummy_DbLasso',\n",
    "           'Bonus10_pen_DbLasso'])\n",
    "\n",
    "bonus_group2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": false,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
